<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="This course covers the fundamentals of data infrastructure and how technologies fit together to form a process, or pipeline, to refine data into usable datasets. This course focuses on building a predictive modeling pipeline used by the various types of projects that are called, “big data.”"><meta name=author content="Bellevue University"><link href=https://bellevue-university.github.io/dsc650/faq/neural-networks/ rel=canonical><link rel=icon href=../../assets/images/favicon.png><meta name=generator content="mkdocs-1.2.1, mkdocs-material-7.1.9"><title>Neural Networks - DSC 650 &ndash; Big Data</title><link rel=stylesheet href=../../assets/stylesheets/main.ca7ac06f.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.f1a3b89f.min.css><meta name=theme-color content=#7e56c2><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback"><style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style></head> <body dir=ltr data-md-color-scheme data-md-color-primary=deep-purple data-md-color-accent=deep-purple> <script>function __prefix(e){return new URL("../..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#number-of-training-epochs class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="DSC 650 &ndash; Big Data" class="md-header__button md-logo" aria-label="DSC 650 – Big Data" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> DSC 650 &ndash; Big Data </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Neural Networks </span> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query data-md-state=active required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </label> <button type=reset class="md-search__icon md-icon" aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg> </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/bellevue-university/dsc650/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> bellevue-university/dsc650 </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="DSC 650 &ndash; Big Data" class="md-nav__button md-logo" aria-label="DSC 650 – Big Data" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg> </a> DSC 650 &ndash; Big Data </label> <div class=md-nav__source> <a href=https://github.com/bellevue-university/dsc650/ title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg> </div> <div class=md-source__repository> bellevue-university/dsc650 </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> About </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_2 type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2> Setup <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Setup data-md-level=1> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Setup </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../setup/ class=md-nav__link> Overview </a> </li> <li class=md-nav__item> <a href=../../setup/hosted/ class=md-nav__link> Hosted </a> </li> <li class=md-nav__item> <a href=../../setup/windows/ class=md-nav__link> Windows </a> </li> <li class=md-nav__item> <a href=../../setup/macOS/ class=md-nav__link> macOS </a> </li> <li class=md-nav__item> <a href=../../setup/ubuntu/ class=md-nav__link> Ubuntu </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3 type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3> Lessons <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Lessons data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Lessons </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_1 type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1> Ten Week <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Ten Week" data-md-level=2> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Ten Week </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../lessons/10-week/week01/ class=md-nav__link> Week 1 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week02/ class=md-nav__link> Week 2 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week03/ class=md-nav__link> Week 3 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week04/ class=md-nav__link> Week 4 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week05/ class=md-nav__link> Week 5 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week06/ class=md-nav__link> Week 6 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week07/ class=md-nav__link> Week 7 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week08/ class=md-nav__link> Week 8 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week09/ class=md-nav__link> Week 9 </a> </li> <li class=md-nav__item> <a href=../../lessons/10-week/week10/ class=md-nav__link> Week 10 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_2 type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2> Twelve Week <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label="Twelve Week" data-md-level=2> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> Twelve Week </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../lessons/12-week/week01/ class=md-nav__link> Week 1 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week02/ class=md-nav__link> Week 2 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week03/ class=md-nav__link> Week 3 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week04/ class=md-nav__link> Week 4 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week05/ class=md-nav__link> Week 5 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week06/ class=md-nav__link> Week 6 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week07/ class=md-nav__link> Week 7 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week08/ class=md-nav__link> Week 8 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week09/ class=md-nav__link> Week 9 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week10/ class=md-nav__link> Week 10 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week11/ class=md-nav__link> Week 11 </a> </li> <li class=md-nav__item> <a href=../../lessons/12-week/week12/ class=md-nav__link> Week 12 </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_3_3 type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3> Fundamentals <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Fundamentals data-md-level=2> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> Fundamentals </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../lessons/fundamentals/latency/ class=md-nav__link> Latency </a> </li> <li class=md-nav__item> <a href=../../lessons/fundamentals/size/ class=md-nav__link> Size </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../data/ class=md-nav__link> Data Sets </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle" data-md-toggle=__nav_5 type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5> Q&A <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav aria-label=Q&amp;A data-md-level=1> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Q&A </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" data-md-toggle=toc type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> Neural Networks <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> Neural Networks </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#number-of-training-epochs class=md-nav__link> Number of Training Epochs </a> </li> <li class=md-nav__item> <a href=#number-of-hidden-units-and-layers class=md-nav__link> Number of Hidden Units and Layers </a> <nav class=md-nav aria-label="Number of Hidden Units and Layers"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#convolutional-networks class=md-nav__link> Convolutional Networks </a> </li> <li class=md-nav__item> <a href=#densely-connected-networks class=md-nav__link> Densely Connected Networks </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#large-number-of-categories class=md-nav__link> Large Number of Categories </a> </li> <li class=md-nav__item> <a href=#dropout-and-regularization class=md-nav__link> Dropout and Regularization </a> </li> <li class=md-nav__item> <a href=#hyperparameter-selection-and-optimization class=md-nav__link> Hyperparameter Selection and Optimization </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#number-of-training-epochs class=md-nav__link> Number of Training Epochs </a> </li> <li class=md-nav__item> <a href=#number-of-hidden-units-and-layers class=md-nav__link> Number of Hidden Units and Layers </a> <nav class=md-nav aria-label="Number of Hidden Units and Layers"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#convolutional-networks class=md-nav__link> Convolutional Networks </a> </li> <li class=md-nav__item> <a href=#densely-connected-networks class=md-nav__link> Densely Connected Networks </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#large-number-of-categories class=md-nav__link> Large Number of Categories </a> </li> <li class=md-nav__item> <a href=#dropout-and-regularization class=md-nav__link> Dropout and Regularization </a> </li> <li class=md-nav__item> <a href=#hyperparameter-selection-and-optimization class=md-nav__link> Hyperparameter Selection and Optimization </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/bellevue-university/dsc650/edit/master/docs/faq/neural-networks.md title="Edit this page" class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg> </a> <h1>Neural Networks</h1> <h2 id=number-of-training-epochs>Number of Training Epochs<a class=headerlink href=#number-of-training-epochs title="Permanent link">&para;</a></h2> <div class="admonition question"> <p class=admonition-title>Question</p> <p>What is the optimal number of training epochs to use when training a model?</p> </div> <p>A training epoch refers to one sweep through the entire training set.</p> <p>From <a href=https://cs231n.github.io/neural-networks-3>Neural Networks Part 3: Learning and Evaluation</a></p> <p><img alt="Training and validation accuracy" src=https://cs231n.github.io/assets/nn3/accuracies.jpeg> </p> <blockquote> <p>Two possible cases are shown in the diagram on the left. The blue validation error curve shows very small validation accuracy compared to the training accuracy, indicating strong overfitting (note, it's possible for the validation accuracy to even start to go down after some point). When you see this in practice you probably want to increase regularization (stronger <span><span class=MathJax_Preview>L2</span><script type=math/tex>L2</script></span> weight penalty, more dropout, etc.) or collect more data. The other possible case is when the validation accuracy tracks the training accuracy fairly well. This case indicates that your model capacity is not high enough: make the model larger by increasing the number of parameters. </p> </blockquote> <h2 id=number-of-hidden-units-and-layers>Number of Hidden Units and Layers<a class=headerlink href=#number-of-hidden-units-and-layers title="Permanent link">&para;</a></h2> <div class="admonition question"> <p class=admonition-title>Question</p> <p>What is the optimal number of hidden units and layers to use when training a model?</p> </div> <p>From <a href=https://web.stanford.edu/~hastie/ElemStatLearn/ >Elements of Statistical learning</a></p> <blockquote> <p>Generally speaking it is better to have too many hidden units than too few. With too few hidden units, the model might not have enough flexibility to capture the nonlinearities in the data; with too many hidden units, the extra weights can be shrunk toward zero if appropriate regularization is used. Typically the number of hidden units is somewhere in the range of 5 to 100, with the number increasing with the number of inputs and number of training cases. It is most common to put down a reasonably large number of units and train them with regularization. Some researchers use cross-validation to estimate the optimal number, but this seems unnecessary if cross-validation is used to estimate the regularization parameter. Choice of the number of hidden layers is guided by background knowledge and experimentation. Each layer extracts features of the input for regression or classification. Use of multiple hidden layers allows construction of hierarchical features at different levels of resolution.</p> </blockquote> <h3 id=convolutional-networks>Convolutional Networks<a class=headerlink href=#convolutional-networks title="Permanent link">&para;</a></h3> <p>See <a href=https://cs231n.github.io/convolutional-networks/#layersizepat>layer sizing patterns</a> for information on the number of layers for convolutional networks.</p> <p>From <a href=https://cs231n.github.io/neural-networks-1>Neural Networks Part 1: Setting up the Architecture</a></p> <blockquote> <p>To give you some context, modern Convolutional Networks contain on orders of 100 million parameters and are usually made up of approximately 10-20 layers (hence deep learning). However, as we will see the number of effective connections is significantly greater due to parameter sharing.</p> </blockquote> <p>From <a href=https://cs231n.github.io/convolutional-networks/ >Convolutional Neural Networks</a></p> <blockquote> <p>In practice: use whatever works best on ImageNet. If you’re feeling a bit of a fatigue in thinking about the architectural decisions, you’ll be pleased to know that in 90% or more of applications you should not have to worry about these. I like to summarize this point as “don’t be a hero”: Instead of rolling your own architecture for a problem, you should look at whatever architecture currently works best on ImageNet, download a pretrained model and finetune it on your data. You should rarely ever have to train a ConvNet from scratch or design one from scratch.</p> </blockquote> <p>From <a href=https://arxiv.org/abs/1512.03385>Deep Residual Learning for Image Recognition</a></p> <blockquote> <p>Exploring Over 1000 layers. We explore an aggressively deep model of over 1000 layers. We set n = 200 that leads to a 1202-layer network, which is trained as described above. Our method shows no optimization difficulty, and this 103-layer network is able to achieve training error &lt;0.1% (Fig. 6, right). Its test error is still fairly good (7.93%, Table 6).</p> <p>But there are still open problems on such aggressively deep models. The testing result of this 1202-layer network is worse than that of our 110-layer network, although both have similar training error. We argue that this is because of overfitting. The 1202-layer network may be unnecessarily large (19.4M) for this small dataset. Strong regularization such as maxout [10] or dropout [14] is applied to obtain the best results ([10, 25, 24, 35]) on this dataset. In this paper, we use no maxout/dropout and just simply impose regularization via deep and thin architectures by design, without distracting from the focus on the difficulties of optimization. But combining with stronger regularization may improve results, which we will study in the future.</p> </blockquote> <p>From <a href=https://cs231n.github.io/neural-networks-1>Neural Networks Part 1: Setting up the Architecture</a></p> <blockquote> <p>The takeaway is that you should not be using smaller networks because you are afraid of overfitting. Instead, you should use as big of a neural network as your computational budget allows, and use other regularization techniques to control overfitting.</p> </blockquote> <h3 id=densely-connected-networks>Densely Connected Networks<a class=headerlink href=#densely-connected-networks title="Permanent link">&para;</a></h3> <p>From <a href=https://cs231n.github.io/neural-networks-1>Neural Networks Part 1: Setting up the Architecture</a></p> <blockquote> <p>As an aside, in practice it is often the case that 3-layer neural networks will outperform 2-layer nets, but going even deeper (4,5,6-layer) rarely helps much more. This is in stark contrast to Convolutional Networks, where depth has been found to be an extremely important component for a good recognition system (e.g. on order of 10 learnable layers). One argument for this observation is that images contain hierarchical structure (e.g. faces are made up of eyes, which are made up of edges, etc.), so several layers of processing make intuitive sense for this data domain.</p> </blockquote> <h2 id=large-number-of-categories>Large Number of Categories<a class=headerlink href=#large-number-of-categories title="Permanent link">&para;</a></h2> <div class="admonition question"> <p class=admonition-title>Question</p> <p>What is the best practices when trying to train models to classify large numbers of categories?</p> </div> <p>From <a href=https://web.stanford.edu/~hastie/ElemStatLearn/ >Elements of Statistical learning</a></p> <blockquote> <p>With <span><span class=MathJax_Preview>N</span><script type=math/tex>N</script></span> observations, <span><span class=MathJax_Preview>p</span><script type=math/tex>p</script></span> predictors,<span><span class=MathJax_Preview>M</span><script type=math/tex>M</script></span> hidden units and <span><span class=MathJax_Preview>L</span><script type=math/tex>L</script></span> training epochs, a neural network fit typically requires <span><span class=MathJax_Preview>O(NpML)</span><script type=math/tex>O(NpML)</script></span> operations. </p> </blockquote> <p>From <a href=https://cs231n.github.io/neural-networks-2>Neural Networks Part 2: Setting up the Data and the Loss</a></p> <blockquote> <p>Problem: Large number of classes. When the set of labels is very large (e.g. words in English dictionary, or ImageNet which contains 22,000 categories), computing the full softmax probabilities becomes expensive. For certain applications, approximate versions are popular. For instance, it may be helpful to use Hierarchical Softmax in natural language processing tasks (see one explanation here (pdf)). The hierarchical softmax decomposes words as labels in a tree. Each label is then represented as a path along the tree, and a Softmax classifier is trained at every node of the tree to disambiguate between the left and right branch. The structure of the tree strongly impacts the performance and is generally problem-dependent.</p> </blockquote> <h2 id=dropout-and-regularization>Dropout and Regularization<a class=headerlink href=#dropout-and-regularization title="Permanent link">&para;</a></h2> <div class="admonition question"> <p class=admonition-title>Question</p> <p>What is the best practice for using dropout and regularization?</p> </div> <p>From <a href=https://cs231n.github.io/neural-networks-1>Neural Networks Part 1: Setting up the Architecture</a></p> <blockquote> <p>. . . there are many other preferred ways to prevent overfitting in Neural Networks that we will discuss later (such as L2 regularization, dropout, input noise). In practice, it is always better to use these methods to control overfitting instead of the number of neurons.</p> <p>To reiterate, the regularization strength is the preferred way to control the overfitting of a neural network.</p> </blockquote> <p>From <a href=https://cs231n.github.io/neural-networks-2>Neural Networks Part 2: Setting up the Data and the Loss</a></p> <blockquote> <p>In practice: It is most common to use a single, global L2 regularization strength that is cross-validated. It is also common to combine this with dropout applied after all layers. The value of p=0.5 is a reasonable default, but this can be tuned on validation data.</p> </blockquote> <p>From <a href=https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</a></p> <blockquote> <p>It is to be expected that dropping units will reduce the capacity of a neural network. If <em>n</em> is the number of hidden units in any layer and <em>p</em> is the probability of retaining a unit, then instead of <em>n</em> hidden units, only <em>pn</em> units will be present after dropout, in expectation. Moreover, this set of <em>pn</em> units will be different each time and the units are not allowed to build co-adaptations freely. Therefore, if an <em>n</em>-sized layer is optimal for a standard neural net on any given task, a good dropout net should have at least <em>n=p</em> units. We found this to be a useful heuristic for setting the number of hidden units in both convolutional and fully connected networks.</p> </blockquote> <h2 id=hyperparameter-selection-and-optimization>Hyperparameter Selection and Optimization<a class=headerlink href=#hyperparameter-selection-and-optimization title="Permanent link">&para;</a></h2> <div class="admonition question"> <p class=admonition-title>Question</p> <p>How do you select and optimize Hyperparameters? </p> </div> <p>See <a href=https://cs231n.github.io/neural-networks-3/#hyper>hyperparameter optimization</a> and <a href=http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf>Random Search for Hyper-Parameter Optimization</a> for more information.</p> <p>Here is a short excerpt: </p> <blockquote> <p>Search for good hyperparameters with random search (not grid search). Stage your search from coarse (wide hyperparameter ranges, training only for 1-5 epochs), to fine (narrower rangers, training for many more epochs)</p> </blockquote> <p>You can also look into tools like <a href=http://jaberg.github.io/hyperopt/ >hyperopt</a></p> <hr> <div class=md-source-date> <small> Last update: <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 10, 2020</span> </small> </div> </article> </div> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../data/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Data Sets" rel=prev> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg> </div> <div class=md-footer__title> <div class=md-ellipsis> <span class=md-footer__direction> Previous </span> Data Sets </div> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2018 - 2020 Bellevue University </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-footer-social> <a href=https://github.com/bellevue-university target=_blank rel=noopener title=github.com class=md-footer-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["tabs"], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.477d984a.min.js", "version": null}</script> <script src=../../assets/javascripts/bundle.82b56eb2.min.js></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script> <script src=https://unpkg.com/mermaid@8.4.8/dist/mermaid.min.js></script> </body> </html>